{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R9IqcWe2ZZ_P","executionInfo":{"status":"ok","timestamp":1686733179960,"user_tz":420,"elapsed":22004,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"885f62e4-a942-4758-90dc-9673931d6cb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","source":["# Import Libraries and Data"],"metadata":{"id":"H1TNvpGhdMzc"}},{"cell_type":"code","source":["from torch._C import ThroughputBenchmark\n","import os\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","import glob\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, transforms, utils, models\n","\n","\n","import cv2\n","import plotly.subplots as sp\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve\n","# Training and validation phases are omitted for brevity\n","import torch.nn.functional as F\n","from sklearn.metrics import roc_auc_score\n","\n","import sys\n","from torch.autograd import Variable\n","import torchvision\n","from heapq import nsmallest\n","import time\n","from operator import itemgetter\n","import io\n","\n","# Check if GPU is available and if not, use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","use_cuda = False\n","if torch.cuda.is_available():\n","  use_cuda = True\n","  print(\"use cuda.\")"],"metadata":{"id":"Xp5zLPceZvn3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686733184934,"user_tz":420,"elapsed":4975,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"d3bf7a07-4d2b-4581-ff67-d113d797cb86"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["use cuda.\n"]}]},{"cell_type":"code","source":["path = '/content/drive/Shareddrives/CS260cProject/chest_xray'\n","# train directory\n","train_folder=path+\"/train/\"\n","train_normal_dir=train_folder+\"NORMAL/\"\n","train_pneu_dir=train_folder+\"PNEUMONIA/\"\n","# test directory\n","test_folder=path+\"/test/\"\n","test_normal_dir=test_folder+\"NORMAL/\"\n","test_pneu_dir=test_folder+\"PNEUMONIA/\"\n","# validation directory\n","val_folder=path+\"/val/\"\n","val_normal_dir=val_folder+\"NORMAL/\"\n","val_pneu_dir=val_folder+\"PNEUMONIA/\"\n"],"metadata":{"id":"LJA2zZ8OZvp3","executionInfo":{"status":"ok","timestamp":1686733184934,"user_tz":420,"elapsed":2,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Train Dataset\n","train_class_names=os.listdir(train_folder)\n","print(\"Train class names: %s\" % (train_class_names))\n","# print(\"\\n\")\n","\n","# Validation Dataset\n","val_class_names=os.listdir(val_folder)\n","print(\"Validation class names: %s\" % (val_class_names))\n","\n","# Test Dataset\n","test_class_names=os.listdir(test_folder)\n","print(\"Test class names: %s\" % (test_class_names))\n","# print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOa6UBP1Zvr3","executionInfo":{"status":"ok","timestamp":1686733186996,"user_tz":420,"elapsed":2063,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"5c922f38-7ac0-49ca-aa16-60b46c358457"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Train class names: ['.DS_Store', 'PNEUMONIA', 'NORMAL']\n","Validation class names: ['.DS_Store', 'NORMAL', 'PNEUMONIA']\n","Test class names: ['.DS_Store', 'NORMAL', 'PNEUMONIA']\n"]}]},{"cell_type":"markdown","source":["# Data Extraction"],"metadata":{"id":"qyvTQSC7dbMs"}},{"cell_type":"code","source":["from torch.utils.data import WeightedRandomSampler\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","}\n","\n","data_dir = path\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n","\n","class_sample_counts = np.bincount(image_datasets['train'].targets)\n","class_weights = 1. / torch.tensor(class_sample_counts, dtype=torch.float)\n","class_weights_normalized = class_weights / class_weights.sum()\n","samples_weights = class_weights_normalized[image_datasets['train'].targets]\n","sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n","\n","dataloaders = {\n","    'train': DataLoader(image_datasets['train'], batch_size=32, sampler=sampler, num_workers=4, pin_memory=True),\n","    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=4, pin_memory=True),\n","    'test': DataLoader(image_datasets['test'], batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n","}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n","class_names = image_datasets['train'].classes"],"metadata":{"id":"24Ydvxj0rw1s","executionInfo":{"status":"ok","timestamp":1686733216615,"user_tz":420,"elapsed":29622,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MXY-kOT1sNzm","executionInfo":{"status":"ok","timestamp":1686619366535,"user_tz":420,"elapsed":518,"user":{"displayName":"ZEYU TAN","userId":"02890442618241445207"}},"outputId":"3d96e21f-654c-4203-a806-4d0f9cdcb7fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['NORMAL', 'PNEUMONIA']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqIHrU07sii6","executionInfo":{"status":"ok","timestamp":1686619368230,"user_tz":420,"elapsed":2,"user":{"displayName":"ZEYU TAN","userId":"02890442618241445207"}},"outputId":"8ac38334-219b-4677-c738-1b0ee46c1fce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['NORMAL', 'PNEUMONIA']"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# EDA"],"metadata":{"id":"DhKzqg-FeczH"}},{"cell_type":"code","source":["# Inspect the first 5 samples\n","# Create a mapping from numerical labels to class names\n","idx_to_class = {v: k for k, v in image_datasets['train'].class_to_idx.items()}\n","\n","# Display images from the training dataset\n","for i in range(5):\n","    image, label = image_datasets['train'][i]\n","\n","    # Convert the numerical label back to a class name\n","    label = idx_to_class[label]\n","    print(f'Image size: {image.size()}')\n","    print(f'Label: {label}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cfbeGQhQpKGl","executionInfo":{"status":"ok","timestamp":1686608332815,"user_tz":420,"elapsed":2194,"user":{"displayName":"MINKAI YANG","userId":"13095676753084550729"}},"outputId":"6eed944f-02c0-4f35-8510-841a58a90af0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image size: torch.Size([3, 224, 224])\n","Label: NORMAL\n","Image size: torch.Size([3, 224, 224])\n","Label: NORMAL\n","Image size: torch.Size([3, 224, 224])\n","Label: NORMAL\n","Image size: torch.Size([3, 224, 224])\n","Label: NORMAL\n","Image size: torch.Size([3, 224, 224])\n","Label: NORMAL\n"]}]},{"cell_type":"code","source":["# Get labels directly from the dataset\n","train_labels = image_datasets['train'].targets\n","val_labels = image_datasets['val'].targets\n","test_labels = image_datasets['test'].targets\n","\n","# Convert numerical labels to their corresponding string labels if necessary\n","# The class_to_idx attribute is a dictionary that maps class names to numerical labels\n","idx_to_class = {v: k for k, v in image_datasets['train'].class_to_idx.items()}\n","train_labels = [idx_to_class[label] for label in train_labels]\n","val_labels = [idx_to_class[label] for label in val_labels]\n","test_labels = [idx_to_class[label] for label in test_labels]\n","\n","fig = make_subplots(rows=1, cols=3, subplot_titles=('Train data', 'Validation data', 'Test data'))\n","\n","# Add traces\n","fig.add_trace(go.Histogram(x=train_labels, nbinsx=2, name='Train'), row=1, col=1)\n","fig.add_trace(go.Histogram(x=val_labels, nbinsx=2, name='Validation'), row=1, col=2)\n","fig.add_trace(go.Histogram(x=test_labels, nbinsx=2, name='Test'), row=1, col=3)\n","\n","# Update layout\n","fig.update_layout(height=400, width=1200, title_text=\"Diagnosis Distribution\")\n","\n","# Show plot\n","fig.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"F8yt1IdltOyq","executionInfo":{"status":"ok","timestamp":1686608333151,"user_tz":420,"elapsed":340,"user":{"displayName":"MINKAI YANG","userId":"13095676753084550729"}},"outputId":"16438ba3-16d5-4692-feed-a82cbb75d2b1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"2c1a5e0c-f10d-455e-8c73-539d41ad379f\" class=\"plotly-graph-div\" style=\"height:400px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2c1a5e0c-f10d-455e-8c73-539d41ad379f\")) {                    Plotly.newPlot(                        \"2c1a5e0c-f10d-455e-8c73-539d41ad379f\",                        [{\"name\":\"Train\",\"nbinsx\":2,\"x\":[\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\"],\"type\":\"histogram\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Validation\",\"nbinsx\":2,\"x\":[\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\"],\"type\":\"histogram\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Test\",\"nbinsx\":2,\"x\":[\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"NORMAL\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\",\"PNEUMONIA\"],\"type\":\"histogram\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2888888888888889]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.7111111111111111,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Train data\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Validation data\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Test data\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Diagnosis Distribution\"},\"height\":400,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('2c1a5e0c-f10d-455e-8c73-539d41ad379f');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["from torchvision.transforms import ToPILImage\n","\n","to_pil = ToPILImage()\n","\n","# Function to denormalize images\n","def denormalize(image):\n","    mean = torch.Tensor([0.485, 0.456, 0.406])\n","    std = torch.Tensor([0.229, 0.224, 0.225])\n","    image = image * std[...,None,None] + mean[...,None,None]\n","    image = image.clamp(0, 1)\n","    return image\n","\n","# Convert tensor image to PIL image\n","def tensor_to_PIL(image):\n","    image = denormalize(image)\n","    image = ToPILImage()(image)\n","    return image\n","\n","idx_to_class = {v: k for k, v in image_datasets['train'].class_to_idx.items()}\n","class_labels = [idx_to_class[label] for label in image_datasets['train'].targets]\n","\n","pneumonia_indices = [i for i, label in enumerate(class_labels) if label == 'Pneumonia'][:4]\n","normal_indices = [i for i, label in enumerate(class_labels) if label == 'Normal'][:4]\n","\n","plt.figure(figsize=(20,8))\n","for i, index in enumerate(pneumonia_indices):\n","    img, label = image_datasets['train'][index]\n","    img = tensor_to_PIL(img)\n","    plt.subplot(2,4,i+1)\n","    plt.axis('off')\n","    plt.imshow(img, cmap='gray')\n","    plt.title('Pneumonia')\n","\n","for i, index in enumerate(normal_indices):\n","    img, label = image_datasets['train'][index]\n","    img = tensor_to_PIL(img)\n","    plt.subplot(2,4,4+i+1)\n","    plt.axis('off')\n","    plt.imshow(img, cmap='gray')\n","    plt.title('Normal')\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"bGip79XFmpRE","executionInfo":{"status":"ok","timestamp":1686608333152,"user_tz":420,"elapsed":11,"user":{"displayName":"MINKAI YANG","userId":"13095676753084550729"}},"outputId":"9d17666d-2a58-4d03-e1f4-03b93fd52b34"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x800 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Filter Pruning"],"metadata":{"id":"Ioi0whHpSjw9"}},{"cell_type":"code","source":["def replace_layers(model, i, indexes, layers):\n","    if i in indexes:\n","        return layers[indexes.index(i)]\n","    return model[i]\n","\n","def prune_conv_layer(model, layer_index, filter_index):\n","    _, conv = list(model.features._modules.items())[layer_index]\n","    next_conv = None\n","    offset = 1\n","\n","    while layer_index + offset < len(model.features._modules.items()):\n","        res =  list(model.features._modules.items())[layer_index+offset]\n","        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n","            next_name, next_conv = res\n","            break\n","        offset = offset + 1\n","\n","    new_conv = \\\n","        torch.nn.Conv2d(in_channels = conv.in_channels, \\\n","            out_channels = conv.out_channels - 1,\n","            kernel_size = conv.kernel_size, \\\n","            stride = conv.stride,\n","            padding = conv.padding,\n","            dilation = conv.dilation,\n","            groups = conv.groups,\n","            bias = (conv.bias is not None))\n","\n","    old_weights = conv.weight.data.cpu().numpy()\n","    new_weights = new_conv.weight.data.cpu().numpy()\n","\n","    new_weights[: filter_index, :, :, :] = old_weights[: filter_index, :, :, :]\n","    new_weights[filter_index : , :, :, :] = old_weights[filter_index + 1 :, :, :, :]\n","    new_conv.weight.data = torch.from_numpy(new_weights)\n","    if use_cuda:\n","        new_conv.weight.data = new_conv.weight.data.cuda()\n","\n","    bias_numpy = conv.bias.data.cpu().numpy()\n","\n","    bias = np.zeros(shape = (bias_numpy.shape[0] - 1), dtype = np.float32)\n","    bias[:filter_index] = bias_numpy[:filter_index]\n","    bias[filter_index : ] = bias_numpy[filter_index + 1 :]\n","    new_conv.bias.data = torch.from_numpy(bias)\n","    if use_cuda:\n","        new_conv.bias.data = new_conv.bias.data.cuda()\n","\n","    if not next_conv is None:\n","        next_new_conv = \\\n","            torch.nn.Conv2d(in_channels = next_conv.in_channels - 1,\\\n","                out_channels =  next_conv.out_channels, \\\n","                kernel_size = next_conv.kernel_size, \\\n","                stride = next_conv.stride,\n","                padding = next_conv.padding,\n","                dilation = next_conv.dilation,\n","                groups = next_conv.groups,\n","                bias = (next_conv.bias is not None))\n","\n","        old_weights = next_conv.weight.data.cpu().numpy()\n","        new_weights = next_new_conv.weight.data.cpu().numpy()\n","\n","        new_weights[:, : filter_index, :, :] = old_weights[:, : filter_index, :, :]\n","        new_weights[:, filter_index : , :, :] = old_weights[:, filter_index + 1 :, :, :]\n","        next_new_conv.weight.data = torch.from_numpy(new_weights)\n","        if use_cuda:\n","            next_new_conv.weight.data = next_new_conv.weight.data.cuda()\n","\n","        next_new_conv.bias.data = next_conv.bias.data\n","\n","    if not next_conv is None:\n","        features = torch.nn.Sequential(\n","                *(replace_layers(model.features, i, [layer_index, layer_index+offset], \\\n","                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n","        del model.features\n","        del conv\n","\n","        model.features = features\n","\n","    else:\n","        #Pruning the last conv layer. This affects the first linear layer of the classifier.\n","        model.features = torch.nn.Sequential(\n","                *(replace_layers(model.features, i, [layer_index], \\\n","                    [new_conv]) for i, _ in enumerate(model.features)))\n","        layer_index = 0\n","        old_linear_layer = None\n","        for _, module in model.classifier._modules.items():\n","            if isinstance(module, torch.nn.Linear):\n","                old_linear_layer = module\n","                break\n","            layer_index = layer_index  + 1\n","\n","        if old_linear_layer is None:\n","            raise BaseException(\"No linear layer found in classifier\")\n","        params_per_input_channel = old_linear_layer.in_features // conv.out_channels\n","\n","        new_linear_layer = \\\n","            torch.nn.Linear(old_linear_layer.in_features - params_per_input_channel,\n","                old_linear_layer.out_features)\n","\n","        old_weights = old_linear_layer.weight.data.cpu().numpy()\n","        new_weights = new_linear_layer.weight.data.cpu().numpy()\n","\n","        new_weights[:, : filter_index * params_per_input_channel] = \\\n","            old_weights[:, : filter_index * params_per_input_channel]\n","        new_weights[:, filter_index * params_per_input_channel :] = \\\n","            old_weights[:, (filter_index + 1) * params_per_input_channel :]\n","\n","        new_linear_layer.bias.data = old_linear_layer.bias.data\n","\n","        new_linear_layer.weight.data = torch.from_numpy(new_weights)\n","        if use_cuda:\n","            new_linear_layer.weight.data = new_linear_layer.weight.data.cuda()\n","\n","        classifier = torch.nn.Sequential(\n","            *(replace_layers(model.classifier, i, [layer_index], \\\n","                [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n","\n","        del model.classifier\n","        del next_conv\n","        del conv\n","        model.classifier = classifier\n","\n","    return model"],"metadata":{"id":"nv4_zTVbOkUK","executionInfo":{"status":"ok","timestamp":1686733216615,"user_tz":420,"elapsed":5,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class FilterPruner:\n","    def __init__(self, model):\n","        self.model = model\n","        self.reset()\n","\n","    def reset(self):\n","        self.filter_ranks = {}\n","\n","    def forward(self, x):\n","        self.activations = []\n","        self.gradients = []\n","        self.grad_index = 0\n","        self.activation_to_layer = {}\n","\n","        activation_index = 0\n","        for layer, (name, module) in enumerate(self.model.features._modules.items()):\n","            x = module(x)\n","            if isinstance(module, torch.nn.modules.conv.Conv2d):\n","                x.register_hook(self.compute_rank)\n","                self.activations.append(x)\n","                self.activation_to_layer[activation_index] = layer\n","                activation_index += 1\n","\n","        return self.model.classifier(x.view(x.size(0), -1))\n","\n","    def compute_rank(self, grad):\n","        activation_index = len(self.activations) - self.grad_index - 1\n","        activation = self.activations[activation_index]\n","\n","        taylor = activation * grad\n","        # Get the average value for every filter,\n","        # accross all the other dimensions\n","        taylor = taylor.mean(dim=(0, 2, 3)).data\n","\n","\n","        if activation_index not in self.filter_ranks:\n","            self.filter_ranks[activation_index] = \\\n","                torch.FloatTensor(activation.size(1)).zero_()\n","\n","            if use_cuda:\n","                self.filter_ranks[activation_index] = self.filter_ranks[activation_index].cuda()\n","\n","        self.filter_ranks[activation_index] += taylor\n","        self.grad_index += 1\n","\n","    def lowest_ranking_filters(self, num):\n","        data = []\n","        for i in sorted(self.filter_ranks.keys()):\n","            for j in range(self.filter_ranks[i].size(0)):\n","                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n","\n","        return nsmallest(num, data, itemgetter(2))\n","\n","    def normalize_ranks_per_layer(self):\n","        for i in self.filter_ranks:\n","            v = torch.abs(self.filter_ranks[i])\n","            v = v.cpu()\n","            v = v / np.sqrt(torch.sum(v * v))\n","            self.filter_ranks[i] = v.cpu()\n","\n","    def get_pruning_plan(self, num_filters_to_prune):\n","        filters_to_prune = self.lowest_ranking_filters(num_filters_to_prune)\n","\n","        # After each of the k filters are pruned,\n","        # the filter index of the next filters change since the model is smaller.\n","        filters_to_prune_per_layer = {}\n","        for (l, f, _) in filters_to_prune:\n","            if l not in filters_to_prune_per_layer:\n","                filters_to_prune_per_layer[l] = []\n","            filters_to_prune_per_layer[l].append(f)\n","\n","        for l in filters_to_prune_per_layer:\n","            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n","            for i in range(len(filters_to_prune_per_layer[l])):\n","                filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n","\n","        filters_to_prune = []\n","        for l in filters_to_prune_per_layer:\n","            for i in filters_to_prune_per_layer[l]:\n","                filters_to_prune.append((l, i))\n","\n","        return filters_to_prune\n","\n","class PruningFineTuner:\n","    def __init__(self, model):\n","        # self.train_data_loader = dataset.loader(train_path)\n","        # self.test_data_loader = dataset.test_loader(test_path)\n","\n","        self.model = model\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","        self.pruner = FilterPruner(self.model)\n","        self.model.train()\n","\n","    def test(self):\n","        self.model.eval() # Set the model to evaluation mode\n","        test_correct = 0\n","        test_total = 0\n","\n","        test_preds = []\n","        test_probs = []\n","        test_labels = []\n","\n","        with torch.no_grad(): # We don't need gradients for the test phase\n","            for inputs, labels in dataloaders['test']:\n","                if use_cuda:\n","                    inputs = inputs.cuda()\n","                    labels = labels.cuda()\n","                # inputs = inputs.to(device)\n","                # labels = labels.to(device)\n","\n","                outputs = self.model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","\n","                test_total += labels.size(0)\n","                test_correct += (preds == labels).sum().item()\n","\n","                # Collect predictions and labels for test set\n","                test_preds.extend(preds.cpu().numpy())\n","                test_probs.extend(outputs[:, 1].cpu().numpy())  # Save the probability of the positive class\n","                test_labels.extend(labels.data.cpu().numpy())\n","\n","        print('-' * 10)\n","        print('Accuracy on the test set: %d %%' % (100 * test_correct / test_total))\n","\n","        # Calculate precision, recall, and F1-score for the test set\n","        test_preds = np.array(test_preds)\n","        test_probs = np.array(test_probs) # Convert to numpy array\n","        test_labels = np.array(test_labels)\n","\n","        test_precision = precision_score(test_labels, test_preds)\n","        test_recall = recall_score(test_labels, test_preds)\n","        test_f1 = f1_score(test_labels, test_preds)\n","        test_auc = roc_auc_score(test_labels, test_probs) # Here we compute the AUC score using the test labels and predicted probabilities\n","\n","        print('Test Precision: {:.4f} Recall: {:.4f} F1-score: {:.4f} AUC: {:.4f}'.format(test_precision, test_recall, test_f1, test_auc))\n","\n","        # Get the best threshold for the precision-recall curve\n","        precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n","\n","        # Compute F1 score for each threshold\n","        f1_scores = 2*recall*precision / (recall + precision)\n","\n","        # Get the threshold that gives the maximum F1 score\n","        best_threshold = thresholds[np.argmax(f1_scores)]\n","        print('Best Threshold: ', best_threshold)\n","\n","        self.model.train()\n","\n","    def train(self, optimizer = None, epoches=7):\n","        if optimizer is None:\n","            optimizer = optim.Adam(self.model.classifier.parameters(), lr=0.001)\n","\n","        for i in range(epoches):\n","            # print(\"Epoch: \", i)\n","            print('Epoch {}/{}'.format(i+1, epoches))\n","            print('-' * 10)\n","            self.train_epoch(optimizer, phase = 'train')\n","            self.train_epoch(optimizer, phase = \"val\")\n","\n","        self.test()\n","        print(\"Finished training\")\n","\n","    def train_epoch(self, optimizer = None, rank_filters = False, phase = 'train'):\n","        # for i, (batch, label) in enumerate(self.train_data_loader):\n","        # self.train_batch(optimizer, batch, label, rank_filters)\n","\n","        if phase == 'train':\n","            self.model.train()  # Set model to training mode\n","        else:\n","            self.model.eval()   # Set model to evaluate mode\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Iterate over data\n","        for inputs, labels in dataloaders[phase]:\n","            if use_cuda:\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","\n","            if (rank_filters):\n","                self.model.zero_grad()\n","            else:\n","                # Zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","            # Forward\n","            # Track history if only in train\n","            with torch.set_grad_enabled(phase == 'train'):\n","                if (phase == 'train'):\n","                    # When pruning filters, use the pruner's forward function\n","                    if rank_filters:\n","                        outputs = self.pruner.forward(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        loss = self.criterion(outputs, labels)\n","                        loss.backward()\n","                    # Backward + optimize only if in training phase\n","                    else:\n","                        outputs = self.model(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        loss = self.criterion(outputs, labels)\n","                        loss.backward()\n","                        optimizer.step()\n","                # Eval\n","                else:\n","                    outputs = self.model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = self.criterion(outputs, labels)\n","\n","            # Statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        # Don't print the results when ranking filters\n","        if not rank_filters:\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","        # Calculate precision, recall, and F1-score\n","        preds_cpu = preds.cpu().numpy()\n","        labels_cpu = labels.data.cpu().numpy()\n","\n","        precision = precision_score(labels_cpu, preds_cpu)\n","        recall = recall_score(labels_cpu, preds_cpu)\n","        f1 = f1_score(labels_cpu, preds_cpu)\n","\n","\n","    def get_candidates_to_prune(self, num_filters_to_prune):\n","        self.pruner.reset()\n","        self.train_epoch(rank_filters = True, phase = \"train\")\n","        self.pruner.normalize_ranks_per_layer()\n","        return self.pruner.get_pruning_plan(num_filters_to_prune)\n","\n","    def total_num_filters(self):\n","        filters = 0\n","        for name, module in self.model.features._modules.items():\n","            if isinstance(module, torch.nn.modules.conv.Conv2d):\n","                filters = filters + module.out_channels\n","\n","        return filters\n","\n","    def prune(self):\n","        # Get the accuracy before pruning\n","        self.test()\n","        self.model.train()\n","\n","        #Make sure all the layers are trainable\n","        for param in self.model.features.parameters():\n","            param.requires_grad = True\n","\n","        number_of_filters = self.total_num_filters()\n","        print(\"Number of filters: \", number_of_filters)\n","        num_filters_to_prune_per_iteration = 512\n","        iterations = int(float(number_of_filters) / num_filters_to_prune_per_iteration)\n","\n","        iterations = int(iterations * 2.0 / 3)\n","\n","        print(\"Number of pruning iterations to reduce 67% filters: \", iterations)\n","\n","        for i in range(iterations):\n","            print(\"\\nPruning iteration: \", i+1)\n","            print(\"Ranking filters... \")\n","            prune_targets = self.get_candidates_to_prune(num_filters_to_prune_per_iteration)\n","            layers_pruned = {}\n","            for layer_index, filter_index in prune_targets:\n","                if layer_index not in layers_pruned:\n","                    layers_pruned[layer_index] = 0\n","                layers_pruned[layer_index] = layers_pruned[layer_index] + 1\n","\n","            print(\"Layers that will be pruned\", layers_pruned)\n","            print(\"Pruning filters... \")\n","            model = self.model.cpu()\n","            for layer_index, filter_index in prune_targets:\n","                model = prune_conv_layer(model, layer_index, filter_index)\n","\n","            self.model = model\n","            if use_cuda:\n","                self.model = self.model.cuda()\n","\n","            # message = str(100*float(self.total_num_filters()) / number_of_filters) + \"%\"\n","            print(\"Number of filters after pruning: \", self.total_num_filters())\n","            self.test()\n","            print(\"Fine tuning to recover from pruning iteration...\")\n","            optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n","            self.train(optimizer, epoches=3)\n","\n","\n","        # print(\"Finished. Fine tune the model a bit more...\")\n","        # self.train(optimizer, epoches=3)\n","        torch.save(model.state_dict(), \"model_pruned\")"],"metadata":{"id":"eYpzAvhRIMqC","executionInfo":{"status":"ok","timestamp":1686736030859,"user_tz":420,"elapsed":499,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"p0xbe37pStMR"}},{"cell_type":"markdown","source":["# VGG16"],"metadata":{"id":"LVkiyu0axuo_"}},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve\n","\n","# Check if GPU is available and if not, use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained VGG16, and freeze the weights\n","vgg16 = models.vgg16(pretrained=True)\n","for param in vgg16.features.parameters():\n","    param.requires_grad = False\n","\n","# Modify the classifier layer to match the number of classes in the dataset\n","num_features = vgg16.classifier[6].in_features\n","features = list(vgg16.classifier.children())[:-1]  # Remove last layer\n","features.extend([nn.Linear(num_features, len(class_names))])  # Add our layer with 2 outputs\n","vgg16.classifier = nn.Sequential(*features)  # Replace the model classifier\n","\n","# Move the model to the device\n","# vgg16 = vgg16.to(device)\n","\n","# Define the loss and the optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","# Only parameters of the final layer are being optimized\n","optimizer = optim.Adam(vgg16.classifier.parameters(), lr=0.001)\n","\n","# Number of epochs\n","epochs = 7\n","\n","# Train the model\n","model = vgg16\n","if use_cuda:\n","    model = model.cuda()\n","fine_tuner = PruningFineTuner(model)\n","fine_tuner.train(epoches=epochs)\n","torch.save(model, \"model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f7a5beff-cbc2-4c25-beea-2971dc8b0c85","id":"I5OhI18tibg3","executionInfo":{"status":"ok","timestamp":1686734730579,"user_tz":420,"elapsed":1513967,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|| 528M/528M [00:02<00:00, 194MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/7\n","----------\n","train Loss: 0.5130 Acc: 0.8248\n","val Loss: 1.2163 Acc: 0.6250\n","Epoch 2/7\n","----------\n","train Loss: 0.3899 Acc: 0.8679\n","val Loss: 0.8042 Acc: 0.5625\n","Epoch 3/7\n","----------\n","train Loss: 0.3582 Acc: 0.8731\n","val Loss: 0.7016 Acc: 0.7500\n","Epoch 4/7\n","----------\n","train Loss: 0.3626 Acc: 0.8760\n","val Loss: 0.2206 Acc: 0.9375\n","Epoch 5/7\n","----------\n","train Loss: 0.3156 Acc: 0.8953\n","val Loss: 0.1624 Acc: 0.9375\n","Epoch 6/7\n","----------\n","train Loss: 0.3191 Acc: 0.8944\n","val Loss: 0.3325 Acc: 0.8750\n","Epoch 7/7\n","----------\n","train Loss: 0.3241 Acc: 0.8834\n","val Loss: 0.2760 Acc: 0.9375\n","----------\n","Accuracy on the test set: 88 %\n","Test Precision: 0.8514 Recall: 0.9846 F1-score: 0.9132 AUC: 0.9607\n","Best Threshold:  0.7226939\n","Finished training\n"]}]},{"cell_type":"code","source":["# Calculate the number of parameters after training\n","def count_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    return total_params, trainable_params\n","\n","total_params, trainable_params = count_parameters(model)\n","print(f\"Total parameters before pruning: {total_params}\")\n","print(f\"Trainable parameters before pruning: {trainable_params}\")\n","\n","def model_size_in_MB(model):\n","    buffer = io.BytesIO()\n","    torch.save(model.state_dict(), buffer)\n","    return buffer.tell() / (1024 * 1024)  # Convert bytes to MB\n","\n","model_size = model_size_in_MB(model)\n","print(f\"Model size before pruning: {model_size} MB\")\n","\n","# Measure the inference time\n","# input, label = next(iter(dataloaders[\"test\"]))\n","# if use_cuda:\n","#     input = input.cuda()\n","\n","t0 = time.time()\n","fine_tuner.test()\n","print(\"The inference took\", time.time() - t0, \"sec\")"],"metadata":{"id":"PcHCreLTqS7t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686734734989,"user_tz":420,"elapsed":4414,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"dc3966fa-a2b5-4623-b7a1-a3f4e31ee529"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters before pruning: 134268738\n","Trainable parameters before pruning: 119554050\n","Model size before pruning: 512.2047166824341 MB\n","----------\n","Accuracy on the test set: 88 %\n","Test Precision: 0.8514 Recall: 0.9846 F1-score: 0.9132 AUC: 0.9607\n","Best Threshold:  0.7226939\n","The inference took 3.9122323989868164 sec\n"]}]},{"cell_type":"code","source":["# Prune the model\n","model = torch.load(\"model\", map_location=lambda storage, loc: storage)\n","if use_cuda:\n","    model = model.cuda()\n","fine_tuner = PruningFineTuner(model)\n","fine_tuner.prune()"],"metadata":{"id":"AJ8SU3MVrAvB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686737052379,"user_tz":420,"elapsed":1011791,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"613ea07d-ae23-47f1-b0ef-761c83fcbbc5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["----------\n","Accuracy on the test set: 88 %\n","Test Precision: 0.8514 Recall: 0.9846 F1-score: 0.9132 AUC: 0.9607\n","Best Threshold:  0.7226939\n","Number of filters:  4224\n","Number of pruning iterations to reduce 67% filters:  5\n","\n","Pruning iteration:  1\n","Ranking filters... \n","Layers that will be pruned {17: 59, 21: 64, 28: 113, 19: 65, 24: 80, 10: 20, 14: 11, 12: 10, 26: 70, 7: 6, 2: 4, 0: 4, 5: 6}\n","Pruning filters... \n","Number of filters after pruning:  3712\n","----------\n","Accuracy on the test set: 89 %\n","Test Precision: 0.8854 Recall: 0.9513 F1-score: 0.9172 AUC: 0.9588\n","Best Threshold:  0.3281502\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.9538 Acc: 0.6089\n","val Loss: 0.5149 Acc: 0.7500\n","Epoch 2/3\n","----------\n","train Loss: 0.5203 Acc: 0.7690\n","val Loss: 0.5392 Acc: 0.6875\n","Epoch 3/3\n","----------\n","train Loss: 0.4676 Acc: 0.8090\n","val Loss: 0.8477 Acc: 0.6250\n","----------\n","Accuracy on the test set: 73 %\n","Test Precision: 0.7121 Recall: 0.9641 F1-score: 0.8192 AUC: 0.8894\n","Best Threshold:  0.49108574\n","Finished training\n","\n","Pruning iteration:  2\n","Ranking filters... \n","Layers that will be pruned {2: 1, 7: 1, 12: 9, 14: 87, 17: 133, 19: 230, 21: 51}\n","Pruning filters... \n","Number of filters after pruning:  3200\n","----------\n","Accuracy on the test set: 73 %\n","Test Precision: 0.7121 Recall: 0.9641 F1-score: 0.8192 AUC: 0.8894\n","Best Threshold:  0.49110323\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.4453 Acc: 0.8246\n","val Loss: 0.9757 Acc: 0.6250\n","Epoch 2/3\n","----------\n","train Loss: 0.3949 Acc: 0.8384\n","val Loss: 0.9238 Acc: 0.6250\n","Epoch 3/3\n","----------\n","train Loss: 0.3288 Acc: 0.8727\n","val Loss: 1.0578 Acc: 0.6250\n","----------\n","Accuracy on the test set: 79 %\n","Test Precision: 0.7749 Recall: 0.9359 F1-score: 0.8479 AUC: 0.8955\n","Best Threshold:  0.49630773\n","Finished training\n","\n","Pruning iteration:  3\n","Ranking filters... \n","Layers that will be pruned {2: 2, 5: 1, 7: 13, 10: 8, 12: 40, 14: 52, 17: 42, 19: 102, 21: 206, 24: 46}\n","Pruning filters... \n","Number of filters after pruning:  2688\n","----------\n","Accuracy on the test set: 79 %\n","Test Precision: 0.7749 Recall: 0.9359 F1-score: 0.8479 AUC: 0.8955\n","Best Threshold:  0.49630484\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.3520 Acc: 0.8612\n","val Loss: 2.1051 Acc: 0.6250\n","Epoch 2/3\n","----------\n","train Loss: 0.3717 Acc: 0.8574\n","val Loss: 1.1408 Acc: 0.6250\n","Epoch 3/3\n","----------\n","train Loss: 0.3156 Acc: 0.8813\n","val Loss: 2.0637 Acc: 0.6250\n","----------\n","Accuracy on the test set: 72 %\n","Test Precision: 0.7000 Recall: 0.9692 F1-score: 0.8129 AUC: 0.8938\n","Best Threshold:  1.3670771\n","Finished training\n","\n","Pruning iteration:  4\n","Ranking filters... \n","Layers that will be pruned {2: 2, 5: 5, 7: 15, 10: 50, 12: 39, 14: 37, 17: 41, 19: 73, 21: 126, 24: 124}\n","Pruning filters... \n","Number of filters after pruning:  2176\n","----------\n","Accuracy on the test set: 72 %\n","Test Precision: 0.7000 Recall: 0.9692 F1-score: 0.8129 AUC: 0.8938\n","Best Threshold:  1.3670748\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.3493 Acc: 0.8654\n","val Loss: 1.9390 Acc: 0.6250\n","Epoch 2/3\n","----------\n","train Loss: 0.3030 Acc: 0.8829\n","val Loss: 1.3884 Acc: 0.6250\n","Epoch 3/3\n","----------\n","train Loss: 0.3070 Acc: 0.8834\n","val Loss: 1.0542 Acc: 0.6250\n","----------\n","Accuracy on the test set: 85 %\n","Test Precision: 0.8371 Recall: 0.9487 F1-score: 0.8894 AUC: 0.9171\n","Best Threshold:  0.5555899\n","Finished training\n","\n","Pruning iteration:  5\n","Ranking filters... \n","Layers that will be pruned {2: 6, 5: 2, 7: 5, 10: 8, 12: 22, 14: 11, 17: 15, 19: 14, 21: 24, 24: 175, 26: 230}\n","Pruning filters... \n","Number of filters after pruning:  1664\n","----------\n","Accuracy on the test set: 85 %\n","Test Precision: 0.8371 Recall: 0.9487 F1-score: 0.8894 AUC: 0.9171\n","Best Threshold:  0.5555899\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.3076 Acc: 0.8850\n","val Loss: 1.3080 Acc: 0.5625\n","Epoch 2/3\n","----------\n","train Loss: 0.3023 Acc: 0.8844\n","val Loss: 0.9076 Acc: 0.5625\n","Epoch 3/3\n","----------\n","train Loss: 0.2892 Acc: 0.8905\n","val Loss: 0.9303 Acc: 0.5625\n","----------\n","Accuracy on the test set: 84 %\n","Test Precision: 0.8156 Recall: 0.9641 F1-score: 0.8837 AUC: 0.9164\n","Best Threshold:  0.25637606\n","Finished training\n"]}]},{"cell_type":"code","source":["# Calculate the number of parameters and model size after pruning\n","total_params, trainable_params = count_parameters(model)\n","print(f\"Total parameters after pruning: {total_params}\")\n","print(f\"Trainable parameters after pruning: {trainable_params}\")\n","\n","model_size = model_size_in_MB(model)\n","print(f\"Model size after pruning: {model_size} MB\")\n","\n","# Measure the inference time\n","# input, label = next(iter(dataloaders[\"test\"]))\n","# if use_cuda:\n","#     input = input.cuda()\n","\n","t0 = time.time()\n","fine_tuner.test()\n","print(\"The inference took\", time.time() - t0)"],"metadata":{"id":"jV3ikHs3qYa0","executionInfo":{"status":"ok","timestamp":1686737058324,"user_tz":420,"elapsed":4880,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5754bcdc-d7ca-4d73-f86c-40f0a6e9fc5e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters after pruning: 98600067\n","Trainable parameters after pruning: 98600067\n","Model size after pruning: 376.13910388946533 MB\n","----------\n","Accuracy on the test set: 84 %\n","Test Precision: 0.8156 Recall: 0.9641 F1-score: 0.8837 AUC: 0.9164\n","Best Threshold:  0.25637606\n","The inference took 4.13808274269104\n"]}]},{"cell_type":"markdown","source":["## VGG19"],"metadata":{"id":"H_2FMFW3gsMj"}},{"cell_type":"code","source":["# Load pre-trained VGG16, and freeze the weights\n","vgg19 = models.vgg19(pretrained=True)\n","for param in vgg19.features.parameters():\n","  param.requires_grad = False\n","\n","# Modify the classifier layer to match the number of classes in the dataset\n","num_features = vgg19.classifier[6].in_features\n","features = list(vgg19.classifier.children())[:-1] # Remove last layer\n","features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 2 outputs\n","vgg19.classifier = nn.Sequential(*features) # Replace the model classifier\n","\n","# Define the loss and the optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","# Only parameters of the final layer are being optimized\n","optimizer = optim.Adam(vgg19.classifier.parameters(), lr=0.001)\n","\n","# Number of epochs\n","epochs = 7\n","\n","# Train the model\n","model = vgg19\n","if use_cuda:\n","    model = model.cuda()\n","fine_tuner = PruningFineTuner(model)\n","fine_tuner.train(epoches=epochs)\n","torch.save(model, \"model\")"],"metadata":{"id":"nLzmNtcY3DMY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686737352284,"user_tz":420,"elapsed":293964,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"7d3ea85e-a71c-4c47-fadf-ce5adb6c6897"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","100%|| 548M/548M [00:02<00:00, 215MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/7\n","----------\n","train Loss: 0.5103 Acc: 0.8152\n","val Loss: 0.3220 Acc: 0.8750\n","Epoch 2/7\n","----------\n","train Loss: 0.3691 Acc: 0.8689\n","val Loss: 1.0814 Acc: 0.6875\n","Epoch 3/7\n","----------\n","train Loss: 0.3743 Acc: 0.8645\n","val Loss: 0.3261 Acc: 0.8750\n","Epoch 4/7\n","----------\n","train Loss: 0.3398 Acc: 0.8786\n","val Loss: 0.1964 Acc: 0.8750\n","Epoch 5/7\n","----------\n","train Loss: 0.3229 Acc: 0.8821\n","val Loss: 0.2729 Acc: 0.8750\n","Epoch 6/7\n","----------\n","train Loss: 0.3256 Acc: 0.8924\n","val Loss: 0.6272 Acc: 0.8750\n","Epoch 7/7\n","----------\n","train Loss: 0.3502 Acc: 0.8806\n","val Loss: 0.3589 Acc: 0.8750\n","----------\n","Accuracy on the test set: 86 %\n","Test Precision: 0.8337 Recall: 0.9769 F1-score: 0.8996 AUC: 0.9562\n","Best Threshold:  0.8324729\n","Finished training\n"]}]},{"cell_type":"code","source":["# Calculate the number of parameters after training\n","def count_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    return total_params, trainable_params\n","\n","total_params, trainable_params = count_parameters(model)\n","print(f\"Total parameters before pruning: {total_params}\")\n","print(f\"Trainable parameters before pruning: {trainable_params}\")\n","\n","def model_size_in_MB(model):\n","    buffer = io.BytesIO()\n","    torch.save(model.state_dict(), buffer)\n","    return buffer.tell() / (1024 * 1024)  # Convert bytes to MB\n","\n","model_size = model_size_in_MB(model)\n","print(f\"Model size before pruning: {model_size} MB\")\n","\n","# Measure the inference time\n","# input, label = next(iter(dataloaders[\"test\"]))\n","# if use_cuda:\n","#     input = input.cuda()\n","\n","t0 = time.time()\n","# output = model(input)\n","fine_tuner.test()\n","print(\"The inference took\", time.time() - t0, \"sec\")"],"metadata":{"id":"RA6A1yT83dI6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686737357131,"user_tz":420,"elapsed":4865,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"6fc411ca-18f3-42f3-d96e-8c99e5a3c247"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters before pruning: 139578434\n","Trainable parameters before pruning: 119554050\n","Model size before pruning: 532.4615964889526 MB\n","----------\n","Accuracy on the test set: 86 %\n","Test Precision: 0.8337 Recall: 0.9769 F1-score: 0.8996 AUC: 0.9562\n","Best Threshold:  0.8324729\n","The inference took 4.070988893508911 sec\n"]}]},{"cell_type":"code","source":["# Prune the model\n","model = torch.load(\"model\", map_location=lambda storage, loc: storage)\n","if use_cuda:\n","    model = model.cuda()\n","fine_tuner = PruningFineTuner(model)\n","fine_tuner.prune()"],"metadata":{"id":"QTVQcgic3fkA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686738515880,"user_tz":420,"elapsed":495242,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"a91c9d8e-406a-4cd1-9484-898652eb727d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["----------\n","Accuracy on the test set: 86 %\n","Test Precision: 0.8337 Recall: 0.9769 F1-score: 0.8996 AUC: 0.9562\n","Best Threshold:  0.8324729\n","Number of filters:  5504\n","Number of pruning iterations to reduce 67% filters:  6\n","\n","Pruning iteration:  1\n","Ranking filters... \n","Layers that will be pruned {2: 3, 34: 88, 32: 78, 28: 65, 25: 60, 19: 42, 10: 11, 30: 54, 23: 40, 21: 37, 12: 10, 0: 3, 16: 6, 14: 12, 5: 1, 7: 2}\n","Pruning filters... \n","Number of filters after pruning:  4992\n","----------\n","Accuracy on the test set: 84 %\n","Test Precision: 0.8246 Recall: 0.9641 F1-score: 0.8889 AUC: 0.9347\n","Best Threshold:  0.51193506\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 21.2640 Acc: 0.5606\n","val Loss: 0.6938 Acc: 0.5000\n","Epoch 2/3\n","----------\n","train Loss: 0.8185 Acc: 0.5849\n","val Loss: 0.5867 Acc: 0.7500\n","Epoch 3/3\n","----------\n","train Loss: 0.7427 Acc: 0.5652\n","val Loss: 0.6613 Acc: 0.6250\n","----------\n","Accuracy on the test set: 53 %\n","Test Precision: 0.9904 Recall: 0.2641 F1-score: 0.4170 AUC: 0.9047\n","Best Threshold:  -0.11455175\n","Finished training\n","\n","Pruning iteration:  2\n","Ranking filters... \n","Layers that will be pruned {7: 1, 10: 8, 12: 92, 14: 111, 16: 170, 19: 130}\n","Pruning filters... \n","Number of filters after pruning:  4480\n","----------\n","Accuracy on the test set: 53 %\n","Test Precision: 0.9904 Recall: 0.2641 F1-score: 0.4170 AUC: 0.9047\n","Best Threshold:  -0.11455111\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.5244 Acc: 0.7540\n","val Loss: 0.9932 Acc: 0.6250\n","Epoch 2/3\n","----------\n","train Loss: 0.4202 Acc: 0.8265\n","val Loss: 2.2665 Acc: 0.6250\n","Epoch 3/3\n","----------\n","train Loss: 0.3628 Acc: 0.8564\n","val Loss: 0.8308 Acc: 0.6250\n","----------\n","Accuracy on the test set: 79 %\n","Test Precision: 0.7895 Recall: 0.9231 F1-score: 0.8511 AUC: 0.8873\n","Best Threshold:  0.5791022\n","Finished training\n","\n","Pruning iteration:  3\n","Ranking filters... \n","Layers that will be pruned {2: 3, 5: 1, 7: 7, 10: 1, 12: 28, 14: 2, 16: 33, 19: 217, 21: 220}\n","Pruning filters... \n","Number of filters after pruning:  3968\n","----------\n","Accuracy on the test set: 79 %\n","Test Precision: 0.7895 Recall: 0.9231 F1-score: 0.8511 AUC: 0.8873\n","Best Threshold:  0.57909423\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.3722 Acc: 0.8576\n","val Loss: 0.4821 Acc: 0.7500\n","Epoch 2/3\n","----------\n","train Loss: 0.7978 Acc: 0.6867\n","val Loss: 0.5865 Acc: 0.6875\n","Epoch 3/3\n","----------\n","train Loss: 0.3993 Acc: 0.8395\n","val Loss: 0.8260 Acc: 0.6250\n","----------\n","Accuracy on the test set: 80 %\n","Test Precision: 0.7978 Recall: 0.9205 F1-score: 0.8548 AUC: 0.8903\n","Best Threshold:  0.6686481\n","Finished training\n","\n","Pruning iteration:  4\n","Ranking filters... \n","Layers that will be pruned {2: 2, 5: 23, 7: 27, 10: 60, 12: 11, 14: 24, 16: 18, 19: 25, 21: 192, 23: 130}\n","Pruning filters... \n","Number of filters after pruning:  3456\n","----------\n","Accuracy on the test set: 80 %\n","Test Precision: 0.7978 Recall: 0.9205 F1-score: 0.8548 AUC: 0.8903\n","Best Threshold:  0.66865474\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.4060 Acc: 0.8340\n","val Loss: 0.8383 Acc: 0.6250\n","Epoch 2/3\n","----------\n","train Loss: 0.3586 Acc: 0.8530\n","val Loss: 1.4636 Acc: 0.6250\n","Epoch 3/3\n","----------\n","train Loss: 0.3269 Acc: 0.8717\n","val Loss: 0.6509 Acc: 0.6250\n","----------\n","Accuracy on the test set: 81 %\n","Test Precision: 0.8009 Recall: 0.9385 F1-score: 0.8642 AUC: 0.9036\n","Best Threshold:  0.24320164\n","Finished training\n","\n","Pruning iteration:  5\n","Ranking filters... \n","Layers that will be pruned {2: 3, 5: 3, 7: 6, 10: 9, 12: 1, 14: 16, 16: 5, 19: 18, 21: 26, 23: 306, 25: 119}\n","Pruning filters... \n","Number of filters after pruning:  2944\n","----------\n","Accuracy on the test set: 81 %\n","Test Precision: 0.8009 Recall: 0.9385 F1-score: 0.8642 AUC: 0.9036\n","Best Threshold:  0.24320558\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.3622 Acc: 0.8545\n","val Loss: 2.3563 Acc: 0.5000\n","Epoch 2/3\n","----------\n","train Loss: 0.3228 Acc: 0.8733\n","val Loss: 0.6482 Acc: 0.6250\n","Epoch 3/3\n","----------\n","train Loss: 0.3052 Acc: 0.8790\n","val Loss: 1.2708 Acc: 0.5000\n","----------\n","Accuracy on the test set: 71 %\n","Test Precision: 0.6882 Recall: 0.9846 F1-score: 0.8101 AUC: 0.8916\n","Best Threshold:  1.1664428\n","Finished training\n","\n","Pruning iteration:  6\n","Ranking filters... \n","Layers that will be pruned {7: 3, 10: 1, 14: 13, 16: 6, 19: 5, 21: 8, 23: 9, 25: 288, 28: 179}\n","Pruning filters... \n","Number of filters after pruning:  2432\n","----------\n","Accuracy on the test set: 71 %\n","Test Precision: 0.6882 Recall: 0.9846 F1-score: 0.8101 AUC: 0.8916\n","Best Threshold:  1.1664287\n","Fine tuning to recover from pruning iteration...\n","Epoch 1/3\n","----------\n","train Loss: 0.3188 Acc: 0.8781\n","val Loss: 1.4094 Acc: 0.5625\n","Epoch 2/3\n","----------\n","train Loss: 0.3074 Acc: 0.8806\n","val Loss: 0.4992 Acc: 0.7500\n","Epoch 3/3\n","----------\n","train Loss: 0.2979 Acc: 0.8865\n","val Loss: 0.3829 Acc: 0.7500\n","----------\n","Accuracy on the test set: 83 %\n","Test Precision: 0.9152 Recall: 0.8026 F1-score: 0.8552 AUC: 0.9137\n","Best Threshold:  1.5683963\n","Finished training\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-12-ec0929f224ef>:141: RuntimeWarning: invalid value encountered in true_divide\n","  f1_scores = 2*recall*precision / (recall + precision)\n"]}]},{"cell_type":"code","source":["# Calculate the number of parameters and model size after pruning\n","total_params, trainable_params = count_parameters(model)\n","print(f\"Total parameters after pruning: {total_params}\")\n","print(f\"Trainable parameters after pruning: {trainable_params}\")\n","\n","model_size = model_size_in_MB(model)\n","print(f\"Model size after pruning: {model_size} MB\")\n","\n","# Measure the inference time\n","t0 = time.time()\n","output = fine_tuner.test()\n","print(\"The inference took\", time.time() - t0)"],"metadata":{"id":"1Q_ZEm_B3h62","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686738520538,"user_tz":420,"elapsed":4661,"user":{"displayName":"Invincible Vader","userId":"11713574443829877877"}},"outputId":"e9fffe15-ff7f-4e05-f85d-8e1341bdbe06"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters after pruning: 107140297\n","Trainable parameters after pruning: 107140297\n","Model size after pruning: 408.7192258834839 MB\n","----------\n","Accuracy on the test set: 83 %\n","Test Precision: 0.9152 Recall: 0.8026 F1-score: 0.8552 AUC: 0.9137\n","Best Threshold:  1.5683963\n","The inference took 3.997321367263794\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-12-ec0929f224ef>:141: RuntimeWarning: invalid value encountered in true_divide\n","  f1_scores = 2*recall*precision / (recall + precision)\n"]}]},{"cell_type":"markdown","source":["## ResNet-50"],"metadata":{"id":"xgbVQVd-oCS3"}},{"cell_type":"markdown","source":["### Transfer Learning"],"metadata":{"id":"yA8bwKK2pspB"}},{"cell_type":"code","source":["resnet50 = models.resnet50(pretrained=True)\n","for param in resnet50.parameters():\n","    param.requires_grad = False\n","\n","# Modify the classifier layer to match the number of classes in the dataset\n","num_features = resnet50.fc.in_features\n","resnet50.fc = nn.Sequential(\n","    nn.Linear(num_features, 512),   # first linear layer\n","    nn.ReLU(),\n","\n","    nn.Linear(512, 256),   # first linear layer\n","    nn.ReLU(),\n","\n","    nn.Linear(256, 128),        # second linear layer\n","    nn.ReLU(),\n","\n","    nn.Linear(128, 2)           # third linear layer, output size = 2\n",")\n","\n","# Move the model to the device\n","resnet50 = resnet50.to(device)\n","\n","# Define the loss and the optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","# Only parameters of the final layer are being optimized\n","optimizer = optim.SGD(resnet50.fc.parameters(), lr=0.001, momentum=0.3)\n","\n","# Number of epochs\n","epochs = 12\n","\n","# Training loop\n","for epoch in range(epochs):\n","    print('Epoch {}/{}'.format(epoch+1, epochs))\n","    print('-' * 10)\n","\n","    for phase in ['train', 'val']:\n","        if phase == 'train':\n","            resnet50.train()  # Set model to training mode\n","        else:\n","            resnet50.eval()   # Set model to evaluate mode\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Iterate over data\n","        for inputs, labels in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # Forward\n","            # Track history if only in train\n","            with torch.set_grad_enabled(phase == 'train'):\n","                outputs = resnet50(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","\n","                # Backward + optimize only if in training phase\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # Statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n"],"metadata":{"id":"Wpa3mrzuZv8a","executionInfo":{"status":"error","timestamp":1686533050142,"user_tz":420,"elapsed":1265531,"user":{"displayName":"ZEYU TAN","userId":"02890442618241445207"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"13c0aa9b-469e-4f30-c28f-2426984a93a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","----------\n","train Loss: 0.6840 Acc: 0.5991\n","val Loss: 0.6642 Acc: 0.7500\n","Epoch 2/12\n","----------\n","train Loss: 0.6290 Acc: 0.7659\n","val Loss: 0.5521 Acc: 0.6875\n","Epoch 3/12\n","----------\n","train Loss: 0.4849 Acc: 0.8002\n","val Loss: 0.6036 Acc: 0.7500\n","Epoch 4/12\n","----------\n","train Loss: 0.4344 Acc: 0.8016\n","val Loss: 0.5823 Acc: 0.6250\n","Epoch 5/12\n","----------\n","train Loss: 0.4143 Acc: 0.8160\n","val Loss: 0.7473 Acc: 0.7500\n","Epoch 6/12\n","----------\n","train Loss: 0.3985 Acc: 0.8265\n","val Loss: 0.6865 Acc: 0.7500\n","Epoch 7/12\n","----------\n","train Loss: 0.4012 Acc: 0.8225\n","val Loss: 0.6493 Acc: 0.7500\n","Epoch 8/12\n","----------\n","train Loss: 0.3920 Acc: 0.8269\n","val Loss: 0.7215 Acc: 0.7500\n","Epoch 9/12\n","----------\n","train Loss: 0.4010 Acc: 0.8196\n","val Loss: 0.6420 Acc: 0.7500\n","Epoch 10/12\n","----------\n","train Loss: 0.3888 Acc: 0.8288\n","val Loss: 0.7677 Acc: 0.7500\n","Epoch 11/12\n","----------\n","train Loss: 0.3992 Acc: 0.8257\n","val Loss: 0.7682 Acc: 0.6875\n","Epoch 12/12\n","----------\n","train Loss: 0.3912 Acc: 0.8292\n","val Loss: 0.5785 Acc: 0.7500\n","----------\n","Accuracy on the test set: 85 %\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2bb83155f918>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mtest_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Here we compute the AUC score using the test labels and predicted probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Precision: {:.4f} Recall: {:.4f} F1-score: {:.4f} AUC: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"]}]},{"cell_type":"code","source":["\n","# Training and validation phases are omitted for brevity\n","\n","resnet50.eval() # Set the model to evaluation mode\n","test_correct = 0\n","test_total = 0\n","\n","test_preds = []\n","test_probs = []\n","test_labels = []\n","\n","with torch.no_grad(): # We don't need gradients for the test phase\n","    for inputs, labels in dataloaders['test']:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = resnet50(inputs)\n","        _, preds = torch.max(outputs, 1)\n","\n","        test_total += labels.size(0)\n","        test_correct += (preds == labels).sum().item()\n","\n","        # Collect predictions and labels for test set\n","        test_preds.extend(preds.cpu().numpy())\n","        test_probs.extend(torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy())  # Save the probability of the positive class\n","        test_labels.extend(labels.data.cpu().numpy())\n","\n","print('-' * 10)\n","print('Accuracy on the test set: %d %%' % (100 * test_correct / test_total))\n","\n","# Calculate precision, recall, and F1-score for the test set\n","test_preds = np.array(test_preds)\n","test_probs = np.array(test_probs) # Convert to numpy array\n","test_labels = np.array(test_labels)\n","\n","test_precision = precision_score(test_labels, test_preds)\n","test_recall = recall_score(test_labels, test_preds)\n","test_f1 = f1_score(test_labels, test_preds)\n","test_auc = roc_auc_score(test_labels, test_probs) # Here we compute the AUC score using the test labels and predicted probabilities\n","\n","print('Test Precision: {:.4f} Recall: {:.4f} F1-score: {:.4f} AUC: {:.4f}'.format(test_precision, test_recall, test_f1, test_auc))\n","\n","# Get the best threshold for the precision-recall curve\n","precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n","\n","# Compute F1 score for each threshold\n","f1_scores = 2*recall*precision / (recall + precision)\n","\n","# Get the threshold that gives the maximum F1 score\n","best_threshold = thresholds[np.argmax(f1_scores)]\n","print('Best Threshold: ', best_threshold)"],"metadata":{"id":"PMZ9uGTdOVc5","executionInfo":{"status":"ok","timestamp":1686533403596,"user_tz":420,"elapsed":4286,"user":{"displayName":"ZEYU TAN","userId":"02890442618241445207"}},"outputId":"46e16d85-7bb5-4e43-9a69-d6fed0c19906","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------\n","Accuracy on the test set: 85 %\n","Test Precision: 0.8889 Recall: 0.8821 F1-score: 0.8855 AUC: 0.9378\n","Best Threshold:  0.38178363\n"]}]},{"cell_type":"markdown","source":["### Fine-tuning"],"metadata":{"id":"U8B6oHHWpvS5"}},{"cell_type":"code","source":["resnet50 = models.resnet50(pretrained=True)\n","\n","# Unfreeze the layers you want to fine-tune\n","for param in resnet50.layer3.parameters():\n","    param.requires_grad = True\n","for param in resnet50.layer4.parameters():\n","    param.requires_grad = True\n","\n","# Modify the classifier layer to match the number of classes in the dataset\n","num_features = resnet50.fc.in_features\n","resnet50.fc = nn.Linear(num_features, len(class_names))\n","\n","# Move the model to the device\n","resnet50 = resnet50.to(device)\n","\n","# Define the loss and the optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","# Specify the parameters to optimize and their learning rate\n","optimizer = optim.SGD([\n","    {'params': resnet50.layer3.parameters(), 'lr': 0.001},\n","    {'params': resnet50.layer4.parameters(), 'lr': 0.001},\n","    {'params': resnet50.fc.parameters(), 'lr': 0.01}\n","], momentum=0.9)\n","\n","# Number of epochs\n","epochs = 10\n","\n","# Training loop\n","for epoch in range(epochs):\n","    print('Epoch {}/{}'.format(epoch+1, epochs))\n","    print('-' * 10)\n","\n","    for phase in ['train', 'val']:\n","        if phase == 'train':\n","            resnet50.train()  # Set model to training mode\n","        else:\n","            resnet50.eval()   # Set model to evaluate mode\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Iterate over data\n","        for inputs, labels in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # Forward\n","            # Track history if only in train\n","            with torch.set_grad_enabled(phase == 'train'):\n","                outputs = resnet50(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","\n","                # Backward + optimize only if in training phase\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # Statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","# Training and validation phases are omitted for brevity\n","\n","resnet50.eval() # Set the model to evaluation mode\n","test_correct = 0\n","test_total = 0\n","\n","test_preds = []\n","test_probs = []\n","test_labels = []\n","\n","with torch.no_grad(): # We don't need gradients for the test phase\n","    for inputs, labels in dataloaders['test']:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = resnet50(inputs)\n","        _, preds = torch.max(outputs, 1)\n","\n","        test_total += labels.size(0)\n","        test_correct += (preds == labels).sum().item()\n","\n","        # Collect predictions and labels for test set\n","        test_preds.extend(preds.cpu().numpy())\n","        test_probs.extend(torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy())  # Save the probability of the positive class\n","        test_labels.extend(labels.data.cpu().numpy())\n","\n","print('-' * 10)\n","print('Accuracy on the test set: %d %%' % (100 * test_correct / test_total))\n","\n","# Calculate precision, recall, and F1-score for the test set\n","test_preds = np.array(test_preds)\n","test_probs = np.array(test_probs) # Convert to numpy array\n","test_labels = np.array(test_labels)\n","\n","test_precision = precision_score(test_labels, test_preds)\n","test_recall = recall_score(test_labels, test_preds)\n","test_f1 = f1_score(test_labels, test_preds)\n","test_auc = roc_auc_score(test_labels, test_probs) # Here we compute the AUC score using the test labels and predicted probabilities\n","\n","print('Test Precision: {:.4f} Recall: {:.4f} F1-score: {:.4f} AUC: {:.4f}'.format(test_precision, test_recall, test_f1, test_auc))\n","\n","# Get the best threshold for the precision-recall curve\n","precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n","\n","# Compute F1 score for each threshold\n","f1_scores = 2*recall*precision / (recall + precision)\n","\n","# Get the threshold that gives the maximum F1 score\n","best_threshold = thresholds[np.argmax(f1_scores)]\n","print('Best Threshold: ', best_threshold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2L9TSsjpwiu","executionInfo":{"status":"ok","timestamp":1686424266463,"user_tz":420,"elapsed":376556,"user":{"displayName":"Binrui Shan","userId":"10723331885839054250"}},"outputId":"b114fca6-0641-4327-a233-33dd5c051d9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning:\n","\n","The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning:\n","\n","Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","----------\n","train Loss: 1.0052 Acc: 0.7653\n","val Loss: 0.5696 Acc: 0.6875\n","Epoch 2/10\n","----------\n","train Loss: 0.4107 Acc: 0.8388\n","val Loss: 0.6467 Acc: 0.6875\n","Epoch 3/10\n","----------\n","train Loss: 0.3221 Acc: 0.8735\n","val Loss: 0.4232 Acc: 0.8125\n","Epoch 4/10\n","----------\n","train Loss: 0.2454 Acc: 0.9024\n","val Loss: 0.2026 Acc: 0.9375\n","Epoch 5/10\n","----------\n","train Loss: 0.2210 Acc: 0.9187\n","val Loss: 0.1903 Acc: 0.9375\n","Epoch 6/10\n","----------\n","train Loss: 0.1996 Acc: 0.9260\n","val Loss: 0.2661 Acc: 0.9375\n","Epoch 7/10\n","----------\n","train Loss: 0.1911 Acc: 0.9306\n","val Loss: 0.3723 Acc: 0.8125\n","Epoch 8/10\n","----------\n","train Loss: 0.1773 Acc: 0.9337\n","val Loss: 0.2132 Acc: 0.9375\n","Epoch 9/10\n","----------\n","train Loss: 0.1619 Acc: 0.9377\n","val Loss: 0.2884 Acc: 0.9375\n","Epoch 10/10\n","----------\n","train Loss: 0.1575 Acc: 0.9442\n","val Loss: 0.0705 Acc: 1.0000\n","----------\n","Accuracy on the test set: 94 %\n","Test Precision: 0.9212 Recall: 0.9897 F1-score: 0.9543 AUC: 0.9893\n","Best Threshold:  0.8006818\n"]}]}]}